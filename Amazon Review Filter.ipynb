{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Review Classifier\n",
    "### Importing Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing Amazon Review data\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('reviews_Sports_and_Outdoors_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIXZKN4ACSKI</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>David Briner</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This came in on time and I am veru happy with ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Woks very good</td>\n",
       "      <td>1390694400</td>\n",
       "      <td>01 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1L5P841VIO02V</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jason A. Kramer</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I had a factory Glock tool that I was using fo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Works as well as the factory tool</td>\n",
       "      <td>1328140800</td>\n",
       "      <td>02 2, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB2W04NI4OEAD</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>J. Fernald</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>If you don't have a 3/32 punch or would like t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a punch, that's all.</td>\n",
       "      <td>1330387200</td>\n",
       "      <td>02 28, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A148SVSWKTJKU6</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jusitn A. Watts \"Maverick9614\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This works no better than any 3/32 punch you w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a punch with a Glock logo.</td>\n",
       "      <td>1328400000</td>\n",
       "      <td>02 5, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAWJ6LW9WMOO</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Material Man</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I purchased this thinking maybe I need a speci...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Ok,tool does what a regular punch does.</td>\n",
       "      <td>1366675200</td>\n",
       "      <td>04 23, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                    reviewerName helpful  \\\n",
       "0    AIXZKN4ACSKI  1881509818                    David Briner  [0, 0]   \n",
       "1  A1L5P841VIO02V  1881509818                 Jason A. Kramer  [1, 1]   \n",
       "2   AB2W04NI4OEAD  1881509818                      J. Fernald  [2, 2]   \n",
       "3  A148SVSWKTJKU6  1881509818  Jusitn A. Watts \"Maverick9614\"  [0, 0]   \n",
       "4   AAAWJ6LW9WMOO  1881509818                    Material Man  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This came in on time and I am veru happy with ...      5.0   \n",
       "1  I had a factory Glock tool that I was using fo...      5.0   \n",
       "2  If you don't have a 3/32 punch or would like t...      4.0   \n",
       "3  This works no better than any 3/32 punch you w...      4.0   \n",
       "4  I purchased this thinking maybe I need a speci...      4.0   \n",
       "\n",
       "                                   summary  unixReviewTime   reviewTime  \n",
       "0                           Woks very good      1390694400  01 26, 2014  \n",
       "1        Works as well as the factory tool      1328140800   02 2, 2012  \n",
       "2                It's a punch, that's all.      1330387200  02 28, 2012  \n",
       "3          It's a punch with a Glock logo.      1328400000   02 5, 2012  \n",
       "4  Ok,tool does what a regular punch does.      1366675200  04 23, 2013  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying head of dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the lenght of each review\n",
    "df['length'] = df['reviewText'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding a binary classifier for rating\n",
    "df['good'] = np.where(df['overall'] > 3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAAEXCAYAAADlSlFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUeDaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1583c156278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking the differences in lenght in a good review v bad review\n",
    "df.hist(column='length', by='good', bins=50,figsize=(12,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    253017\n",
       "0     43320\n",
       "Name: good, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking numbers of each type of review\n",
    "df['good'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DownLoading Word Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing library\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    }
   ],
   "source": [
    "# downloading database\n",
    "nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing new database\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  importing string functions\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating fuctions to strip punctuation and remove stop words\n",
    "def text_process(mess):\n",
    "     # Check for punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Removing stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [came, time, veru, happy, haved, used, already...\n",
       "1    [factory, Glock, tool, using, Glock, 26, 27, 1...\n",
       "2    [dont, 332, punch, would, like, one, Glock, ba...\n",
       "3    [works, better, 332, punch, would, find, hardw...\n",
       "4    [purchased, thinking, maybe, need, special, to...\n",
       "5    [Needed, tool, really, break, G22, works, perf...\n",
       "6    [u, dont, Get, need, completely, take, glock, ...\n",
       "7    [light, doubt, capture, attention, nighttime, ...\n",
       "8    [Light, laser, torch, work, well, bright, inst...\n",
       "9    [everything, says, would, like, 34lane34, mark...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing new function\n",
    "df['reviewText'][0:10].apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing Resample\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    43320\n",
       "0    43320\n",
       "Name: good, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "feat_majority = df[df.good==1]\n",
    "feat_minority = df[df.good==0]\n",
    " \n",
    "# Downsample majority class\n",
    "feat_majority_downsampled = resample(feat_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=43320, # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "feat_downsampled = pd.concat([feat_majority_downsampled, feat_minority])\n",
    " \n",
    "# Display new class counts\n",
    "feat_downsampled.good.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Unique Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing tool\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25580\n"
     ]
    }
   ],
   "source": [
    "# fitting function with summary\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(feat_downsampled['summary'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transforming data in to matrix\n",
    "review_bow = bow_transformer.transform(feat_downsampled['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# another library\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fitting review bow\n",
    "tfidf_transformer = TfidfTransformer().fit(review_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86640, 25580)\n"
     ]
    }
   ],
   "source": [
    "review_tfidf = tfidf_transformer.transform(review_bow)\n",
    "print(review_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navie Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# fitting model with transformed words\n",
    "spam_detect_model = MultinomialNB().fit(review_tfidf, feat_downsampled['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving predictions\n",
    "all_predictions = spam_detect_model.predict(review_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.80      0.82     43320\n",
      "          1       0.81      0.85      0.83     43320\n",
      "\n",
      "avg / total       0.83      0.83      0.83     86640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluating predictions\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(feat_downsampled['good'], all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34717  8603]\n",
      " [ 6297 37023]]\n"
     ]
    }
   ],
   "source": [
    "# seeing error types\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print (confusion_matrix(feat_downsampled['good'], all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Analysis\n",
    "\n",
    "After using nltk libraries to extract and fit the unique words in the review summary category we have been able to train a model to 83% accuracy.  However, this model was trained on all the data. When the data should have been split into a test and training group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = feat_downsampled['summary']\n",
    "y = feat_downsampled['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing tool to split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# splitting data in to test and training group\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat_downsampled['summary'], feat_downsampled['good'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing tool to transform data\n",
    "from sklearn.pipeline import Pipeline\n",
    "# transforming data through pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('classifier', MultinomialNB()),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_process at 0x000002646B67AD08>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocesso...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying pipeline as estimator\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving predictions for new model\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6189 1632]\n",
      " [2489 7018]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.79      0.75      7821\n",
      "          1       0.81      0.74      0.77      9507\n",
      "\n",
      "avg / total       0.77      0.76      0.76     17328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing metrics\n",
    "print(confusion_matrix(predictions,y_test))\n",
    "print('\\n')\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etallen127\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\etallen127\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing tool to transform data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up params to test C value and gamma value for best fit\n",
    "param_grid = {'n_estimators':[100,250,500],\n",
    "          'subsample': [0.35, 0.5],\n",
    "          'loss': ['deviance', 'exponential'],\n",
    "         'learning_rate':[0.35, 0.5, 0.65, 0.75, 0.85, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLF = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(CLF,param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transforming data through pipeline\n",
    "pipelinebooster = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('classifier', grid),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLF = GradientBoostingClassifier(learning_rate=0.35, loss='deviance', n_estimators=500, subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76108033,  0.74976916,  0.74630656,  0.74474838,  0.74930748])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipelinebooster, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gradient Boosting Analysis\n",
    "\n",
    "Looking at the Gradient Boosting Model, I was surprised to see that the scores were lower than the random forest model. Since, it is very similar but uses the residuals to test the next decision tree. For this type of model, I thought it would pick up new words through the process, thus improving the classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up params to test C value and gamma value for best fit\n",
    "param_grid = {'n_neighbors': [2,5,25,75,150,250,500],\n",
    "              'weights': ['uniform','distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(KNN,param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing tool to transform data\n",
    "from sklearn.pipeline import Pipeline\n",
    "# transforming data through pipeline\n",
    "pipelineneighbors = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('classifier', grid),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "[CV] n_neighbors=2, weights=uniform ..................................\n"
     ]
    }
   ],
   "source": [
    "pipelineneighbors.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transforming data through pipeline\n",
    "pipelineknn = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('classifier', knn),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(pipelineknn.fit(X_train, y_train), X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analysis\n",
    "\n",
    "Unfortunately I was un able to complete a test on this type of model. It would just cause my computer to crash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up params to test C value and gamma value for best fit\n",
    "param_grid = {'n_estimators': [2,5,25,75,150]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(rfc,param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transforming data through pipeline\n",
    "pipelinetrees = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('classifier', grid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transforming data through pipeline\n",
    "pipelinetrees = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('classifier', RFC )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76552401,  0.75796399,  0.75877193,  0.75467452,  0.75825254])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipelinetrees.fit(X_train, y_train), X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Analysis\n",
    "\n",
    "For the random forest model, I was surprised to see no improvement from the Baynes model.  It is possible that with more estimators results could have been improved, but at the expense of a lot more computing power. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After, using the nltk library to isolate key words in 43,000 Amazon Review.  We then made 4 types of model to try and properly predicted weither a review was positive or negative.  The top preforming model was the baynes model. Which applies a set list of word to filter for and classify if present. This model was trained to 82%. After that we trained an gradient boosted model.Which learns from many weak model and tries to learn from each, applying its residuals to the next model. After all the models are tested the scores are average to generate a prediction. This model acheived 74-75% accuracy. Then we created a similar model, a random forest classifier but it was able to preform a bit better with 76% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
